{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\NBH\\Anaconda3\\envs\\violence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\Users\\NBH\\Anaconda3\\envs\\violence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\Users\\NBH\\Anaconda3\\envs\\violence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\Users\\NBH\\Anaconda3\\envs\\violence\\lib\\imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\Users\\NBH\\Anaconda3\\envs\\violence\\lib\\imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\violence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\violence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\violence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0m_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\violence\\lib\\imp.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(name, file, filename, details)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\violence\\lib\\imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[1;34m(name, path, file)\u001b[0m\n\u001b[0;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f7e36330d56c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\violence\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\violence\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\violence\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\violence\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\violence\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\violence\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\violence\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcomponent_api_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\violence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 74\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\NBH\\Anaconda3\\envs\\violence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\Users\\NBH\\Anaconda3\\envs\\violence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\Users\\NBH\\Anaconda3\\envs\\violence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\Users\\NBH\\Anaconda3\\envs\\violence\\lib\\imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\Users\\NBH\\Anaconda3\\envs\\violence\\lib\\imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['violent','non_violent']\n",
    "\n",
    "X_train = np.load('C:/Users/NBH/Desktop/violence-detection/30x30_10FPS/train/'+labels[0] + '.npy')\n",
    "y_train = np.zeros(X_train.shape[0])\n",
    "\n",
    "for i, label in enumerate(labels[1:]):\n",
    "    x = np.load('C:/Users/NBH/Desktop/violence-detection/30x30_10FPS/train/'+label + '.npy')\n",
    "    X_train = np.vstack((X_train, x))\n",
    "    y_train = np.append(y_train, np.full(x.shape[0], fill_value= (i + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26745, 30, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('C:/Users/NBH/Desktop/violence-detection/30x30_10FPS/test/'+labels[0] + '.npy')\n",
    "y_test = np.zeros(X_test.shape[0])\n",
    "\n",
    "for i, label in enumerate(labels[1:]):\n",
    "    x = np.load('C:/Users/NBH/Desktop/violence-detection/30x30_10FPS/test/'+label + '.npy')\n",
    "    X_test = np.vstack((X_test, x))\n",
    "    y_test = np.append(y_test, np.full(x.shape[0], fill_value= (i + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3924, 30, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26745, 900)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(900,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(900, activation='sigmoid')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 128)               115328    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 900)               116100    \n",
      "=================================================================\n",
      "Total params: 252,196\n",
      "Trainable params: 252,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26745 samples, validate on 3924 samples\n",
      "Epoch 1/500\n",
      "26745/26745 [==============================] - 2s 86us/step - loss: 7.4411e-05 - val_loss: 8.9116e-05\n",
      "Epoch 2/500\n",
      "26745/26745 [==============================] - 2s 78us/step - loss: 7.4407e-05 - val_loss: 8.9112e-05\n",
      "Epoch 3/500\n",
      "26745/26745 [==============================] - 2s 89us/step - loss: 7.4403e-05 - val_loss: 8.9108e-05\n",
      "Epoch 4/500\n",
      "26745/26745 [==============================] - 2s 74us/step - loss: 7.4399e-05 - val_loss: 8.9104e-05\n",
      "Epoch 5/500\n",
      "26745/26745 [==============================] - 2s 84us/step - loss: 7.4396e-05 - val_loss: 8.9100e-05\n",
      "Epoch 6/500\n",
      "26745/26745 [==============================] - 3s 96us/step - loss: 7.4392e-05 - val_loss: 8.9096e-05\n",
      "Epoch 7/500\n",
      "26745/26745 [==============================] - 2s 90us/step - loss: 7.4388e-05 - val_loss: 8.9092e-05\n",
      "Epoch 8/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.4384e-05 - val_loss: 8.9088e-05\n",
      "Epoch 9/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.4381e-05 - val_loss: 8.9085e-05\n",
      "Epoch 10/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.4377e-05 - val_loss: 8.9081e-05\n",
      "Epoch 11/500\n",
      "26745/26745 [==============================] - 2s 83us/step - loss: 7.4373e-05 - val_loss: 8.9077e-05\n",
      "Epoch 12/500\n",
      "26745/26745 [==============================] - 2s 85us/step - loss: 7.4370e-05 - val_loss: 8.9073e-05\n",
      "Epoch 13/500\n",
      "26745/26745 [==============================] - 2s 80us/step - loss: 7.4366e-05 - val_loss: 8.9069e-05\n",
      "Epoch 14/500\n",
      "26745/26745 [==============================] - 2s 88us/step - loss: 7.4363e-05 - val_loss: 8.9066e-05\n",
      "Epoch 15/500\n",
      "26745/26745 [==============================] - 3s 101us/step - loss: 7.4359e-05 - val_loss: 8.9062e-05\n",
      "Epoch 16/500\n",
      "26745/26745 [==============================] - 2s 74us/step - loss: 7.4356e-05 - val_loss: 8.9058e-05\n",
      "Epoch 17/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4352e-05 - val_loss: 8.9054e-05\n",
      "Epoch 18/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.4349e-05 - val_loss: 8.9051e-05s - loss:\n",
      "Epoch 19/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.4345e-05 - val_loss: 8.9047e-05\n",
      "Epoch 20/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4342e-05 - val_loss: 8.9044e-05\n",
      "Epoch 21/500\n",
      "26745/26745 [==============================] - 2s 77us/step - loss: 7.4339e-05 - val_loss: 8.9040e-05\n",
      "Epoch 22/500\n",
      "26745/26745 [==============================] - 2s 76us/step - loss: 7.4335e-05 - val_loss: 8.9036e-05\n",
      "Epoch 23/500\n",
      "26745/26745 [==============================] - 2s 76us/step - loss: 7.4332e-05 - val_loss: 8.9033e-05\n",
      "Epoch 24/500\n",
      "26745/26745 [==============================] - 2s 78us/step - loss: 7.4328e-05 - val_loss: 8.9029e-05\n",
      "Epoch 25/500\n",
      "26745/26745 [==============================] - 2s 74us/step - loss: 7.4325e-05 - val_loss: 8.9026e-05\n",
      "Epoch 26/500\n",
      "26745/26745 [==============================] - 2s 80us/step - loss: 7.4322e-05 - val_loss: 8.9023e-05\n",
      "Epoch 27/500\n",
      "26745/26745 [==============================] - 2s 89us/step - loss: 7.4319e-05 - val_loss: 8.9019e-05\n",
      "Epoch 28/500\n",
      "26745/26745 [==============================] - 2s 82us/step - loss: 7.4315e-05 - val_loss: 8.9016e-05\n",
      "Epoch 29/500\n",
      "26745/26745 [==============================] - 2s 82us/step - loss: 7.4312e-05 - val_loss: 8.9012e-05\n",
      "Epoch 30/500\n",
      "26745/26745 [==============================] - 2s 83us/step - loss: 7.4309e-05 - val_loss: 8.9009e-05\n",
      "Epoch 31/500\n",
      "26745/26745 [==============================] - 2s 74us/step - loss: 7.4306e-05 - val_loss: 8.9006e-05\n",
      "Epoch 32/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.4303e-05 - val_loss: 8.9002e-05\n",
      "Epoch 33/500\n",
      "26745/26745 [==============================] - 2s 72us/step - loss: 7.4300e-05 - val_loss: 8.8999e-05\n",
      "Epoch 34/500\n",
      "26745/26745 [==============================] - 2s 76us/step - loss: 7.4296e-05 - val_loss: 8.8996e-05\n",
      "Epoch 35/500\n",
      "26745/26745 [==============================] - 2s 69us/step - loss: 7.4293e-05 - val_loss: 8.8993e-05\n",
      "Epoch 36/500\n",
      "26745/26745 [==============================] - 2s 75us/step - loss: 7.4290e-05 - val_loss: 8.8989e-05\n",
      "Epoch 37/500\n",
      "26745/26745 [==============================] - 2s 75us/step - loss: 7.4287e-05 - val_loss: 8.8986e-05\n",
      "Epoch 38/500\n",
      "26745/26745 [==============================] - 2s 81us/step - loss: 7.4284e-05 - val_loss: 8.8983e-05\n",
      "Epoch 39/500\n",
      "26745/26745 [==============================] - 2s 89us/step - loss: 7.4281e-05 - val_loss: 8.8980e-05\n",
      "Epoch 40/500\n",
      "26745/26745 [==============================] - 3s 99us/step - loss: 7.4278e-05 - val_loss: 8.8977e-05\n",
      "Epoch 41/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.4275e-05 - val_loss: 8.8974e-05\n",
      "Epoch 42/500\n",
      "26745/26745 [==============================] - 2s 73us/step - loss: 7.4272e-05 - val_loss: 8.8970e-05\n",
      "Epoch 43/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.4269e-05 - val_loss: 8.8967e-05\n",
      "Epoch 44/500\n",
      "26745/26745 [==============================] - 2s 69us/step - loss: 7.4266e-05 - val_loss: 8.8964e-05\n",
      "Epoch 45/500\n",
      "26745/26745 [==============================] - 2s 61us/step - loss: 7.4264e-05 - val_loss: 8.8961e-05\n",
      "Epoch 46/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.4261e-05 - val_loss: 8.8958e-05\n",
      "Epoch 47/500\n",
      "26745/26745 [==============================] - 2s 75us/step - loss: 7.4258e-05 - val_loss: 8.8955e-05\n",
      "Epoch 48/500\n",
      "26745/26745 [==============================] - 2s 77us/step - loss: 7.4255e-05 - val_loss: 8.8952e-05\n",
      "Epoch 49/500\n",
      "26745/26745 [==============================] - 2s 79us/step - loss: 7.4252e-05 - val_loss: 8.8949e-05\n",
      "Epoch 50/500\n",
      "26745/26745 [==============================] - 2s 72us/step - loss: 7.4249e-05 - val_loss: 8.8946e-05\n",
      "Epoch 51/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.4247e-05 - val_loss: 8.8944e-05\n",
      "Epoch 52/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4244e-05 - val_loss: 8.8941e-05\n",
      "Epoch 53/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.4241e-05 - val_loss: 8.8938e-05\n",
      "Epoch 54/500\n",
      "26745/26745 [==============================] - 2s 79us/step - loss: 7.4238e-05 - val_loss: 8.8935e-05\n",
      "Epoch 55/500\n",
      "26745/26745 [==============================] - 2s 79us/step - loss: 7.4236e-05 - val_loss: 8.8932e-05\n",
      "Epoch 56/500\n",
      "26745/26745 [==============================] - 2s 71us/step - loss: 7.4233e-05 - val_loss: 8.8929e-05\n",
      "Epoch 57/500\n",
      "26745/26745 [==============================] - 2s 70us/step - loss: 7.4230e-05 - val_loss: 8.8927e-05\n",
      "Epoch 58/500\n",
      "26745/26745 [==============================] - 2s 80us/step - loss: 7.4228e-05 - val_loss: 8.8924e-05\n",
      "Epoch 59/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.4225e-05 - val_loss: 8.8921e-05 7.4215e-\n",
      "Epoch 60/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.4222e-05 - val_loss: 8.8918e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4220e-05 - val_loss: 8.8916e-05\n",
      "Epoch 62/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.4217e-05 - val_loss: 8.8913e-05\n",
      "Epoch 63/500\n",
      "26745/26745 [==============================] - 2s 72us/step - loss: 7.4215e-05 - val_loss: 8.8910e-05\n",
      "Epoch 64/500\n",
      "26745/26745 [==============================] - 2s 75us/step - loss: 7.4212e-05 - val_loss: 8.8908e-05\n",
      "Epoch 65/500\n",
      "26745/26745 [==============================] - 2s 76us/step - loss: 7.4210e-05 - val_loss: 8.8905e-05\n",
      "Epoch 66/500\n",
      "26745/26745 [==============================] - 2s 70us/step - loss: 7.4207e-05 - val_loss: 8.8902e-05\n",
      "Epoch 67/500\n",
      "26745/26745 [==============================] - 2s 70us/step - loss: 7.4205e-05 - val_loss: 8.8900e-05\n",
      "Epoch 68/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.4202e-05 - val_loss: 8.8897e-05\n",
      "Epoch 69/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.4200e-05 - val_loss: 8.8894e-05\n",
      "Epoch 70/500\n",
      "26745/26745 [==============================] - 2s 81us/step - loss: 7.4197e-05 - val_loss: 8.8892e-05\n",
      "Epoch 71/500\n",
      "26745/26745 [==============================] - 2s 79us/step - loss: 7.4195e-05 - val_loss: 8.8889e-05\n",
      "Epoch 72/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.4192e-05 - val_loss: 8.8887e-05\n",
      "Epoch 73/500\n",
      "26745/26745 [==============================] - 2s 61us/step - loss: 7.4190e-05 - val_loss: 8.8884e-05\n",
      "Epoch 74/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4187e-05 - val_loss: 8.8882e-05\n",
      "Epoch 75/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.4185e-05 - val_loss: 8.8879e-05\n",
      "Epoch 76/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4183e-05 - val_loss: 8.8876e-05\n",
      "Epoch 77/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4180e-05 - val_loss: 8.8874e-05\n",
      "Epoch 78/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4178e-05 - val_loss: 8.8871e-05\n",
      "Epoch 79/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4175e-05 - val_loss: 8.8869e-05\n",
      "Epoch 80/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4173e-05 - val_loss: 8.8866e-05\n",
      "Epoch 81/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.4171e-05 - val_loss: 8.8864e-05\n",
      "Epoch 82/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.4168e-05 - val_loss: 8.8861e-05\n",
      "Epoch 83/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4166e-05 - val_loss: 8.8859e-05\n",
      "Epoch 84/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4164e-05 - val_loss: 8.8856e-05\n",
      "Epoch 85/500\n",
      "26745/26745 [==============================] - 2s 61us/step - loss: 7.4162e-05 - val_loss: 8.8854e-05\n",
      "Epoch 86/500\n",
      "26745/26745 [==============================] - 2s 61us/step - loss: 7.4159e-05 - val_loss: 8.8852e-05\n",
      "Epoch 87/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4157e-05 - val_loss: 8.8849e-05\n",
      "Epoch 88/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.4155e-05 - val_loss: 8.8847e-05\n",
      "Epoch 89/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4153e-05 - val_loss: 8.8845e-05\n",
      "Epoch 90/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.4151e-05 - val_loss: 8.8842e-05\n",
      "Epoch 91/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4148e-05 - val_loss: 8.8840e-05\n",
      "Epoch 92/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4146e-05 - val_loss: 8.8838e-05\n",
      "Epoch 93/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4144e-05 - val_loss: 8.8835e-05\n",
      "Epoch 94/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4142e-05 - val_loss: 8.8833e-05\n",
      "Epoch 95/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.4140e-05 - val_loss: 8.8831e-05\n",
      "Epoch 96/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4138e-05 - val_loss: 8.8829e-05\n",
      "Epoch 97/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.4136e-05 - val_loss: 8.8827e-05\n",
      "Epoch 98/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4134e-05 - val_loss: 8.8824e-05\n",
      "Epoch 99/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4131e-05 - val_loss: 8.8822e-05\n",
      "Epoch 100/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4129e-05 - val_loss: 8.8820e-05\n",
      "Epoch 101/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.4127e-05 - val_loss: 8.8818e-05\n",
      "Epoch 102/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4125e-05 - val_loss: 8.8816e-05\n",
      "Epoch 103/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4123e-05 - val_loss: 8.8814e-05\n",
      "Epoch 104/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4121e-05 - val_loss: 8.8812e-05\n",
      "Epoch 105/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.4119e-05 - val_loss: 8.8810e-05\n",
      "Epoch 106/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4117e-05 - val_loss: 8.8807e-05\n",
      "Epoch 107/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4115e-05 - val_loss: 8.8805e-05\n",
      "Epoch 108/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4113e-05 - val_loss: 8.8803e-05\n",
      "Epoch 109/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.4112e-05 - val_loss: 8.8801e-05\n",
      "Epoch 110/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4110e-05 - val_loss: 8.8799e-05\n",
      "Epoch 111/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4108e-05 - val_loss: 8.8797e-05\n",
      "Epoch 112/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4106e-05 - val_loss: 8.8795e-05\n",
      "Epoch 113/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4104e-05 - val_loss: 8.8793e-05\n",
      "Epoch 114/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4102e-05 - val_loss: 8.8792e-05\n",
      "Epoch 115/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4100e-05 - val_loss: 8.8790e-05\n",
      "Epoch 116/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4098e-05 - val_loss: 8.8788e-05\n",
      "Epoch 117/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4097e-05 - val_loss: 8.8786e-05\n",
      "Epoch 118/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4095e-05 - val_loss: 8.8784e-05\n",
      "Epoch 119/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4093e-05 - val_loss: 8.8782e-05\n",
      "Epoch 120/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.4091e-05 - val_loss: 8.8780e-05\n",
      "Epoch 121/500\n",
      "26745/26745 [==============================] - 2s 70us/step - loss: 7.4089e-05 - val_loss: 8.8778e-05\n",
      "Epoch 122/500\n",
      "26745/26745 [==============================] - 2s 69us/step - loss: 7.4088e-05 - val_loss: 8.8776e-05\n",
      "Epoch 123/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4086e-05 - val_loss: 8.8775e-05loss: 7.42\n",
      "Epoch 124/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4084e-05 - val_loss: 8.8773e-05\n",
      "Epoch 125/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.4082e-05 - val_loss: 8.8771e-05\n",
      "Epoch 126/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4081e-05 - val_loss: 8.8769e-05\n",
      "Epoch 127/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4079e-05 - val_loss: 8.8767e-05\n",
      "Epoch 128/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4077e-05 - val_loss: 8.8766e-05\n",
      "Epoch 129/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.4075e-05 - val_loss: 8.8764e-05\n",
      "Epoch 130/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4074e-05 - val_loss: 8.8762e-05\n",
      "Epoch 131/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4072e-05 - val_loss: 8.8760e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4070e-05 - val_loss: 8.8759e-05\n",
      "Epoch 133/500\n",
      "26745/26745 [==============================] - 2s 61us/step - loss: 7.4069e-05 - val_loss: 8.8757e-05\n",
      "Epoch 134/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.4067e-05 - val_loss: 8.8755e-05\n",
      "Epoch 135/500\n",
      "26745/26745 [==============================] - 2s 71us/step - loss: 7.4066e-05 - val_loss: 8.8754e-05\n",
      "Epoch 136/500\n",
      "26745/26745 [==============================] - 2s 81us/step - loss: 7.4064e-05 - val_loss: 8.8752e-05\n",
      "Epoch 137/500\n",
      "26745/26745 [==============================] - 2s 77us/step - loss: 7.4062e-05 - val_loss: 8.8750e-05\n",
      "Epoch 138/500\n",
      "26745/26745 [==============================] - 2s 73us/step - loss: 7.4061e-05 - val_loss: 8.8749e-05\n",
      "Epoch 139/500\n",
      "26745/26745 [==============================] - 2s 74us/step - loss: 7.4059e-05 - val_loss: 8.8747e-05\n",
      "Epoch 140/500\n",
      "26745/26745 [==============================] - 2s 69us/step - loss: 7.4058e-05 - val_loss: 8.8745e-05\n",
      "Epoch 141/500\n",
      "26745/26745 [==============================] - 2s 70us/step - loss: 7.4056e-05 - val_loss: 8.8744e-05\n",
      "Epoch 142/500\n",
      "26745/26745 [==============================] - 2s 84us/step - loss: 7.4054e-05 - val_loss: 8.8742e-05\n",
      "Epoch 143/500\n",
      "26745/26745 [==============================] - 2s 81us/step - loss: 7.4053e-05 - val_loss: 8.8741e-05\n",
      "Epoch 144/500\n",
      "26745/26745 [==============================] - 2s 72us/step - loss: 7.4051e-05 - val_loss: 8.8739e-05\n",
      "Epoch 145/500\n",
      "26745/26745 [==============================] - 2s 69us/step - loss: 7.4050e-05 - val_loss: 8.8738e-05\n",
      "Epoch 146/500\n",
      "26745/26745 [==============================] - 2s 61us/step - loss: 7.4048e-05 - val_loss: 8.8736e-05\n",
      "Epoch 147/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4047e-05 - val_loss: 8.8734e-05\n",
      "Epoch 148/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4045e-05 - val_loss: 8.8733e-05\n",
      "Epoch 149/500\n",
      "26745/26745 [==============================] - 2s 70us/step - loss: 7.4044e-05 - val_loss: 8.8731e-05\n",
      "Epoch 150/500\n",
      "26745/26745 [==============================] - 2s 78us/step - loss: 7.4042e-05 - val_loss: 8.8730e-05\n",
      "Epoch 151/500\n",
      "26745/26745 [==============================] - 2s 71us/step - loss: 7.4041e-05 - val_loss: 8.8728e-05\n",
      "Epoch 152/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4039e-05 - val_loss: 8.8727e-05\n",
      "Epoch 153/500\n",
      "26745/26745 [==============================] - 2s 81us/step - loss: 7.4038e-05 - val_loss: 8.8725e-05\n",
      "Epoch 154/500\n",
      "26745/26745 [==============================] - 2s 72us/step - loss: 7.4037e-05 - val_loss: 8.8724e-05\n",
      "Epoch 155/500\n",
      "26745/26745 [==============================] - 2s 73us/step - loss: 7.4035e-05 - val_loss: 8.8723e-05\n",
      "Epoch 156/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.4034e-05 - val_loss: 8.8721e-05\n",
      "Epoch 157/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.4032e-05 - val_loss: 8.8720e-05\n",
      "Epoch 158/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4031e-05 - val_loss: 8.8718e-05\n",
      "Epoch 159/500\n",
      "26745/26745 [==============================] - 2s 71us/step - loss: 7.4030e-05 - val_loss: 8.8717e-05\n",
      "Epoch 160/500\n",
      "26745/26745 [==============================] - 2s 79us/step - loss: 7.4028e-05 - val_loss: 8.8715e-05\n",
      "Epoch 161/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.4027e-05 - val_loss: 8.8714e-05\n",
      "Epoch 162/500\n",
      "26745/26745 [==============================] - 2s 71us/step - loss: 7.4026e-05 - val_loss: 8.8713e-05\n",
      "Epoch 163/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4024e-05 - val_loss: 8.8711e-05\n",
      "Epoch 164/500\n",
      "26745/26745 [==============================] - 2s 61us/step - loss: 7.4023e-05 - val_loss: 8.8710e-05\n",
      "Epoch 165/500\n",
      "26745/26745 [==============================] - 2s 61us/step - loss: 7.4022e-05 - val_loss: 8.8708e-05\n",
      "Epoch 166/500\n",
      "26745/26745 [==============================] - 2s 61us/step - loss: 7.4020e-05 - val_loss: 8.8707e-05\n",
      "Epoch 167/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4019e-05 - val_loss: 8.8706e-05\n",
      "Epoch 168/500\n",
      "26745/26745 [==============================] - 2s 72us/step - loss: 7.4018e-05 - val_loss: 8.8704e-05\n",
      "Epoch 169/500\n",
      "26745/26745 [==============================] - 2s 73us/step - loss: 7.4016e-05 - val_loss: 8.8703e-05\n",
      "Epoch 170/500\n",
      "26745/26745 [==============================] - 2s 83us/step - loss: 7.4015e-05 - val_loss: 8.8702e-05\n",
      "Epoch 171/500\n",
      "26745/26745 [==============================] - 2s 70us/step - loss: 7.4014e-05 - val_loss: 8.8701e-05\n",
      "Epoch 172/500\n",
      "26745/26745 [==============================] - 2s 77us/step - loss: 7.4012e-05 - val_loss: 8.8699e-05\n",
      "Epoch 173/500\n",
      "26745/26745 [==============================] - 2s 72us/step - loss: 7.4011e-05 - val_loss: 8.8698e-05\n",
      "Epoch 174/500\n",
      "26745/26745 [==============================] - 2s 84us/step - loss: 7.4010e-05 - val_loss: 8.8697e-05\n",
      "Epoch 175/500\n",
      "26745/26745 [==============================] - 2s 69us/step - loss: 7.4009e-05 - val_loss: 8.8695e-05\n",
      "Epoch 176/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.4007e-05 - val_loss: 8.8694e-05ss: 7.4049e-0\n",
      "Epoch 177/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4006e-05 - val_loss: 8.8693e-05\n",
      "Epoch 178/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4005e-05 - val_loss: 8.8692e-05\n",
      "Epoch 179/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4004e-05 - val_loss: 8.8691e-05\n",
      "Epoch 180/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4003e-05 - val_loss: 8.8689e-05\n",
      "Epoch 181/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.4001e-05 - val_loss: 8.8688e-05\n",
      "Epoch 182/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.4000e-05 - val_loss: 8.8687e-05\n",
      "Epoch 183/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3999e-05 - val_loss: 8.8686e-05\n",
      "Epoch 184/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3998e-05 - val_loss: 8.8685e-05\n",
      "Epoch 185/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3997e-05 - val_loss: 8.8683e-05\n",
      "Epoch 186/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3996e-05 - val_loss: 8.8682e-05\n",
      "Epoch 187/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3995e-05 - val_loss: 8.8681e-05\n",
      "Epoch 188/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3993e-05 - val_loss: 8.8680e-05\n",
      "Epoch 189/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3992e-05 - val_loss: 8.8679e-05\n",
      "Epoch 190/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3991e-05 - val_loss: 8.8678e-05\n",
      "Epoch 191/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3990e-05 - val_loss: 8.8676e-05\n",
      "Epoch 192/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3989e-05 - val_loss: 8.8675e-05\n",
      "Epoch 193/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3988e-05 - val_loss: 8.8674e-05\n",
      "Epoch 194/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3987e-05 - val_loss: 8.8673e-05\n",
      "Epoch 195/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3986e-05 - val_loss: 8.8672e-05\n",
      "Epoch 196/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3985e-05 - val_loss: 8.8671e-05\n",
      "Epoch 197/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3984e-05 - val_loss: 8.8670e-05\n",
      "Epoch 198/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3982e-05 - val_loss: 8.8669e-05\n",
      "Epoch 199/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3981e-05 - val_loss: 8.8668e-05\n",
      "Epoch 200/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3980e-05 - val_loss: 8.8667e-05\n",
      "Epoch 201/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3979e-05 - val_loss: 8.8666e-05\n",
      "Epoch 202/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3978e-05 - val_loss: 8.8665e-05\n",
      "Epoch 203/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3977e-05 - val_loss: 8.8664e-05\n",
      "Epoch 204/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3976e-05 - val_loss: 8.8663e-05\n",
      "Epoch 205/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3975e-05 - val_loss: 8.8662e-05\n",
      "Epoch 206/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3974e-05 - val_loss: 8.8661e-05\n",
      "Epoch 207/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3973e-05 - val_loss: 8.8660e-05\n",
      "Epoch 208/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3972e-05 - val_loss: 8.8659e-05\n",
      "Epoch 209/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3971e-05 - val_loss: 8.8658e-05\n",
      "Epoch 210/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3970e-05 - val_loss: 8.8657e-05\n",
      "Epoch 211/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3969e-05 - val_loss: 8.8656e-05\n",
      "Epoch 212/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3968e-05 - val_loss: 8.8655e-05\n",
      "Epoch 213/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3967e-05 - val_loss: 8.8654e-05\n",
      "Epoch 214/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3967e-05 - val_loss: 8.8653e-05\n",
      "Epoch 215/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3966e-05 - val_loss: 8.8652e-05\n",
      "Epoch 216/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3965e-05 - val_loss: 8.8651e-05\n",
      "Epoch 217/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3964e-05 - val_loss: 8.8650e-05\n",
      "Epoch 218/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3963e-05 - val_loss: 8.8649e-05\n",
      "Epoch 219/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3962e-05 - val_loss: 8.8648e-05\n",
      "Epoch 220/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3961e-05 - val_loss: 8.8647e-05\n",
      "Epoch 221/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.3960e-05 - val_loss: 8.8646e-05\n",
      "Epoch 222/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3959e-05 - val_loss: 8.8645e-05\n",
      "Epoch 223/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3958e-05 - val_loss: 8.8645e-05\n",
      "Epoch 224/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3957e-05 - val_loss: 8.8644e-05\n",
      "Epoch 225/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3957e-05 - val_loss: 8.8643e-05\n",
      "Epoch 226/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3956e-05 - val_loss: 8.8642e-05\n",
      "Epoch 227/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3955e-05 - val_loss: 8.8641e-05\n",
      "Epoch 228/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3954e-05 - val_loss: 8.8640e-05\n",
      "Epoch 229/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3953e-05 - val_loss: 8.8639e-05\n",
      "Epoch 230/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3952e-05 - val_loss: 8.8639e-05\n",
      "Epoch 231/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3952e-05 - val_loss: 8.8638e-05\n",
      "Epoch 232/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3951e-05 - val_loss: 8.8637e-05\n",
      "Epoch 233/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3950e-05 - val_loss: 8.8636e-05\n",
      "Epoch 234/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3949e-05 - val_loss: 8.8635e-05\n",
      "Epoch 235/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3948e-05 - val_loss: 8.8634e-05\n",
      "Epoch 236/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3947e-05 - val_loss: 8.8634e-05\n",
      "Epoch 237/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3947e-05 - val_loss: 8.8633e-05\n",
      "Epoch 238/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3946e-05 - val_loss: 8.8632e-05\n",
      "Epoch 239/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3945e-05 - val_loss: 8.8631e-05\n",
      "Epoch 240/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3944e-05 - val_loss: 8.8630e-05\n",
      "Epoch 241/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3943e-05 - val_loss: 8.8630e-05\n",
      "Epoch 242/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3943e-05 - val_loss: 8.8629e-05\n",
      "Epoch 243/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3942e-05 - val_loss: 8.8628e-05\n",
      "Epoch 244/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3941e-05 - val_loss: 8.8627e-05\n",
      "Epoch 245/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3940e-05 - val_loss: 8.8627e-05\n",
      "Epoch 246/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3940e-05 - val_loss: 8.8626e-05\n",
      "Epoch 247/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3939e-05 - val_loss: 8.8625e-05\n",
      "Epoch 248/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3938e-05 - val_loss: 8.8624e-05\n",
      "Epoch 249/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3937e-05 - val_loss: 8.8624e-05\n",
      "Epoch 250/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3937e-05 - val_loss: 8.8623e-05\n",
      "Epoch 251/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3936e-05 - val_loss: 8.8622e-05\n",
      "Epoch 252/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3935e-05 - val_loss: 8.8621e-05\n",
      "Epoch 253/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3935e-05 - val_loss: 8.8621e-05\n",
      "Epoch 254/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3934e-05 - val_loss: 8.8620e-05\n",
      "Epoch 255/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3933e-05 - val_loss: 8.8619e-05\n",
      "Epoch 256/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3932e-05 - val_loss: 8.8619e-05\n",
      "Epoch 257/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3932e-05 - val_loss: 8.8618e-05\n",
      "Epoch 258/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3931e-05 - val_loss: 8.8617e-05\n",
      "Epoch 259/500\n",
      "26745/26745 [==============================] - 2s 61us/step - loss: 7.3930e-05 - val_loss: 8.8617e-05\n",
      "Epoch 260/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3930e-05 - val_loss: 8.8616e-05\n",
      "Epoch 261/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3929e-05 - val_loss: 8.8615e-05\n",
      "Epoch 262/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3928e-05 - val_loss: 8.8615e-05\n",
      "Epoch 263/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3928e-05 - val_loss: 8.8614e-05\n",
      "Epoch 264/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3927e-05 - val_loss: 8.8613e-05\n",
      "Epoch 265/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3926e-05 - val_loss: 8.8613e-05\n",
      "Epoch 266/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3926e-05 - val_loss: 8.8612e-05\n",
      "Epoch 267/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3925e-05 - val_loss: 8.8611e-05\n",
      "Epoch 268/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3924e-05 - val_loss: 8.8611e-05\n",
      "Epoch 269/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3924e-05 - val_loss: 8.8610e-05\n",
      "Epoch 270/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3923e-05 - val_loss: 8.8609e-05\n",
      "Epoch 271/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3923e-05 - val_loss: 8.8609e-05\n",
      "Epoch 272/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3922e-05 - val_loss: 8.8608e-05\n",
      "Epoch 273/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3921e-05 - val_loss: 8.8608e-05\n",
      "Epoch 274/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3921e-05 - val_loss: 8.8607e-05\n",
      "Epoch 275/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3920e-05 - val_loss: 8.8606e-05\n",
      "Epoch 276/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3920e-05 - val_loss: 8.8606e-05\n",
      "Epoch 277/500\n",
      "26745/26745 [==============================] - 2s 61us/step - loss: 7.3919e-05 - val_loss: 8.8605e-05\n",
      "Epoch 278/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3918e-05 - val_loss: 8.8605e-05\n",
      "Epoch 279/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3918e-05 - val_loss: 8.8604e-05\n",
      "Epoch 280/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3917e-05 - val_loss: 8.8603e-05\n",
      "Epoch 281/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3917e-05 - val_loss: 8.8603e-05\n",
      "Epoch 282/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3916e-05 - val_loss: 8.8602e-05\n",
      "Epoch 283/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3915e-05 - val_loss: 8.8602e-05\n",
      "Epoch 284/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3915e-05 - val_loss: 8.8601e-05\n",
      "Epoch 285/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3914e-05 - val_loss: 8.8601e-05\n",
      "Epoch 286/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3914e-05 - val_loss: 8.8600e-05\n",
      "Epoch 287/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3913e-05 - val_loss: 8.8600e-05\n",
      "Epoch 288/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3913e-05 - val_loss: 8.8599e-05\n",
      "Epoch 289/500\n",
      "26745/26745 [==============================] - 2s 61us/step - loss: 7.3912e-05 - val_loss: 8.8598e-05\n",
      "Epoch 290/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3912e-05 - val_loss: 8.8598e-05\n",
      "Epoch 291/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3911e-05 - val_loss: 8.8597e-05\n",
      "Epoch 292/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3910e-05 - val_loss: 8.8597e-05\n",
      "Epoch 293/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3910e-05 - val_loss: 8.8596e-05\n",
      "Epoch 294/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3909e-05 - val_loss: 8.8596e-05\n",
      "Epoch 295/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3909e-05 - val_loss: 8.8595e-05\n",
      "Epoch 296/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3908e-05 - val_loss: 8.8595e-05\n",
      "Epoch 297/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3908e-05 - val_loss: 8.8594e-05\n",
      "Epoch 298/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3907e-05 - val_loss: 8.8594e-05\n",
      "Epoch 299/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3907e-05 - val_loss: 8.8593e-05\n",
      "Epoch 300/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3906e-05 - val_loss: 8.8593e-05\n",
      "Epoch 301/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3906e-05 - val_loss: 8.8592e-05\n",
      "Epoch 302/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3905e-05 - val_loss: 8.8592e-05\n",
      "Epoch 303/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3905e-05 - val_loss: 8.8591e-05\n",
      "Epoch 304/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3904e-05 - val_loss: 8.8591e-05\n",
      "Epoch 305/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3904e-05 - val_loss: 8.8590e-05\n",
      "Epoch 306/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3903e-05 - val_loss: 8.8590e-05\n",
      "Epoch 307/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.3903e-05 - val_loss: 8.8590e-05\n",
      "Epoch 308/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3902e-05 - val_loss: 8.8589e-05\n",
      "Epoch 309/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3902e-05 - val_loss: 8.8589e-05\n",
      "Epoch 310/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3901e-05 - val_loss: 8.8588e-05\n",
      "Epoch 311/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3901e-05 - val_loss: 8.8588e-05\n",
      "Epoch 312/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3901e-05 - val_loss: 8.8587e-05\n",
      "Epoch 313/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3900e-05 - val_loss: 8.8587e-05\n",
      "Epoch 314/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3900e-05 - val_loss: 8.8586e-05\n",
      "Epoch 315/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3899e-05 - val_loss: 8.8586e-05\n",
      "Epoch 316/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3899e-05 - val_loss: 8.8586e-05\n",
      "Epoch 317/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.3898e-05 - val_loss: 8.8585e-05\n",
      "Epoch 318/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3898e-05 - val_loss: 8.8585e-05\n",
      "Epoch 319/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3897e-05 - val_loss: 8.8584e-05\n",
      "Epoch 320/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3897e-05 - val_loss: 8.8584e-05\n",
      "Epoch 321/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3897e-05 - val_loss: 8.8583e-05\n",
      "Epoch 322/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3896e-05 - val_loss: 8.8583e-05\n",
      "Epoch 323/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3896e-05 - val_loss: 8.8583e-05\n",
      "Epoch 324/500\n",
      "26745/26745 [==============================] - 2s 69us/step - loss: 7.3895e-05 - val_loss: 8.8582e-05\n",
      "Epoch 325/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3895e-05 - val_loss: 8.8582e-05\n",
      "Epoch 326/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3894e-05 - val_loss: 8.8581e-05\n",
      "Epoch 327/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3894e-05 - val_loss: 8.8581e-05\n",
      "Epoch 328/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3894e-05 - val_loss: 8.8581e-05\n",
      "Epoch 329/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3893e-05 - val_loss: 8.8580e-05\n",
      "Epoch 330/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3893e-05 - val_loss: 8.8580e-05\n",
      "Epoch 331/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3892e-05 - val_loss: 8.8579e-05\n",
      "Epoch 332/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3892e-05 - val_loss: 8.8579e-05\n",
      "Epoch 333/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3892e-05 - val_loss: 8.8579e-05\n",
      "Epoch 334/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3891e-05 - val_loss: 8.8578e-05\n",
      "Epoch 335/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3891e-05 - val_loss: 8.8578e-05\n",
      "Epoch 336/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3890e-05 - val_loss: 8.8578e-05\n",
      "Epoch 337/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3890e-05 - val_loss: 8.8577e-05\n",
      "Epoch 338/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3890e-05 - val_loss: 8.8577e-05\n",
      "Epoch 339/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3889e-05 - val_loss: 8.8576e-05\n",
      "Epoch 340/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3889e-05 - val_loss: 8.8576e-05\n",
      "Epoch 341/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.3889e-05 - val_loss: 8.8576e-05\n",
      "Epoch 342/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3888e-05 - val_loss: 8.8575e-05\n",
      "Epoch 343/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3888e-05 - val_loss: 8.8575e-05\n",
      "Epoch 344/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3887e-05 - val_loss: 8.8575e-05\n",
      "Epoch 345/500\n",
      "26745/26745 [==============================] - 2s 61us/step - loss: 7.3887e-05 - val_loss: 8.8574e-05\n",
      "Epoch 346/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3887e-05 - val_loss: 8.8574e-05\n",
      "Epoch 347/500\n",
      "26745/26745 [==============================] - 2s 61us/step - loss: 7.3886e-05 - val_loss: 8.8574e-05\n",
      "Epoch 348/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3886e-05 - val_loss: 8.8573e-05\n",
      "Epoch 349/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3886e-05 - val_loss: 8.8573e-05\n",
      "Epoch 350/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3885e-05 - val_loss: 8.8573e-05\n",
      "Epoch 351/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3885e-05 - val_loss: 8.8572e-05\n",
      "Epoch 352/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3885e-05 - val_loss: 8.8572e-05\n",
      "Epoch 353/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3884e-05 - val_loss: 8.8572e-05\n",
      "Epoch 354/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3884e-05 - val_loss: 8.8571e-05\n",
      "Epoch 355/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3884e-05 - val_loss: 8.8571e-05\n",
      "Epoch 356/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3883e-05 - val_loss: 8.8571e-05\n",
      "Epoch 357/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3883e-05 - val_loss: 8.8570e-05\n",
      "Epoch 358/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3883e-05 - val_loss: 8.8570e-05\n",
      "Epoch 359/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3882e-05 - val_loss: 8.8570e-05\n",
      "Epoch 360/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3882e-05 - val_loss: 8.8569e-05\n",
      "Epoch 361/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3882e-05 - val_loss: 8.8569e-05\n",
      "Epoch 362/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3881e-05 - val_loss: 8.8569e-05\n",
      "Epoch 363/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3881e-05 - val_loss: 8.8568e-05\n",
      "Epoch 364/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3881e-05 - val_loss: 8.8568e-05\n",
      "Epoch 365/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3880e-05 - val_loss: 8.8568e-05\n",
      "Epoch 366/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3880e-05 - val_loss: 8.8568e-05\n",
      "Epoch 367/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3880e-05 - val_loss: 8.8567e-05\n",
      "Epoch 368/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3880e-05 - val_loss: 8.8567e-05\n",
      "Epoch 369/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3879e-05 - val_loss: 8.8567e-05\n",
      "Epoch 370/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3879e-05 - val_loss: 8.8566e-05\n",
      "Epoch 371/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3879e-05 - val_loss: 8.8566e-05\n",
      "Epoch 372/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3878e-05 - val_loss: 8.8566e-05\n",
      "Epoch 373/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3878e-05 - val_loss: 8.8566e-05\n",
      "Epoch 374/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3878e-05 - val_loss: 8.8565e-05\n",
      "Epoch 375/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3877e-05 - val_loss: 8.8565e-05\n",
      "Epoch 376/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3877e-05 - val_loss: 8.8565e-05\n",
      "Epoch 377/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3877e-05 - val_loss: 8.8565e-05\n",
      "Epoch 378/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3877e-05 - val_loss: 8.8564e-05\n",
      "Epoch 379/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3876e-05 - val_loss: 8.8564e-05\n",
      "Epoch 380/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3876e-05 - val_loss: 8.8564e-05\n",
      "Epoch 381/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3876e-05 - val_loss: 8.8563e-05\n",
      "Epoch 382/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3876e-05 - val_loss: 8.8563e-05\n",
      "Epoch 383/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3875e-05 - val_loss: 8.8563e-05\n",
      "Epoch 384/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3875e-05 - val_loss: 8.8563e-05\n",
      "Epoch 385/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3875e-05 - val_loss: 8.8562e-05\n",
      "Epoch 386/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3874e-05 - val_loss: 8.8562e-05\n",
      "Epoch 387/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3874e-05 - val_loss: 8.8562e-05\n",
      "Epoch 388/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3874e-05 - val_loss: 8.8562e-05\n",
      "Epoch 389/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3874e-05 - val_loss: 8.8561e-05\n",
      "Epoch 390/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3873e-05 - val_loss: 8.8561e-05\n",
      "Epoch 391/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3873e-05 - val_loss: 8.8561e-05\n",
      "Epoch 392/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3873e-05 - val_loss: 8.8561e-05\n",
      "Epoch 393/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3873e-05 - val_loss: 8.8560e-05\n",
      "Epoch 394/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3872e-05 - val_loss: 8.8560e-05\n",
      "Epoch 395/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3872e-05 - val_loss: 8.8560e-05\n",
      "Epoch 396/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3872e-05 - val_loss: 8.8560e-05\n",
      "Epoch 397/500\n",
      "26745/26745 [==============================] - 2s 74us/step - loss: 7.3872e-05 - val_loss: 8.8560e-05\n",
      "Epoch 398/500\n",
      "26745/26745 [==============================] - 2s 84us/step - loss: 7.3871e-05 - val_loss: 8.8559e-05\n",
      "Epoch 399/500\n",
      "26745/26745 [==============================] - 2s 73us/step - loss: 7.3871e-05 - val_loss: 8.8559e-05\n",
      "Epoch 400/500\n",
      "26745/26745 [==============================] - 2s 76us/step - loss: 7.3871e-05 - val_loss: 8.8559e-05\n",
      "Epoch 401/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.3871e-05 - val_loss: 8.8559e-05\n",
      "Epoch 402/500\n",
      "26745/26745 [==============================] - 2s 69us/step - loss: 7.3870e-05 - val_loss: 8.8558e-05\n",
      "Epoch 403/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3870e-05 - val_loss: 8.8558e-05\n",
      "Epoch 404/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3870e-05 - val_loss: 8.8558e-05\n",
      "Epoch 405/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.3870e-05 - val_loss: 8.8558e-05\n",
      "Epoch 406/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.3870e-05 - val_loss: 8.8558e-05\n",
      "Epoch 407/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3869e-05 - val_loss: 8.8557e-05\n",
      "Epoch 408/500\n",
      "26745/26745 [==============================] - 2s 92us/step - loss: 7.3869e-05 - val_loss: 8.8557e-05\n",
      "Epoch 409/500\n",
      "26745/26745 [==============================] - 2s 76us/step - loss: 7.3869e-05 - val_loss: 8.8557e-05\n",
      "Epoch 410/500\n",
      "26745/26745 [==============================] - 2s 73us/step - loss: 7.3869e-05 - val_loss: 8.8557e-05\n",
      "Epoch 411/500\n",
      "26745/26745 [==============================] - 2s 71us/step - loss: 7.3868e-05 - val_loss: 8.8556e-05\n",
      "Epoch 412/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26745/26745 [==============================] - 2s 77us/step - loss: 7.3868e-05 - val_loss: 8.8556e-05\n",
      "Epoch 413/500\n",
      "26745/26745 [==============================] - 2s 73us/step - loss: 7.3868e-05 - val_loss: 8.8556e-05\n",
      "Epoch 414/500\n",
      "26745/26745 [==============================] - 2s 75us/step - loss: 7.3868e-05 - val_loss: 8.8556e-05\n",
      "Epoch 415/500\n",
      "26745/26745 [==============================] - 2s 69us/step - loss: 7.3868e-05 - val_loss: 8.8556e-05\n",
      "Epoch 416/500\n",
      "26745/26745 [==============================] - 2s 75us/step - loss: 7.3867e-05 - val_loss: 8.8555e-05\n",
      "Epoch 417/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.3867e-05 - val_loss: 8.8555e-05\n",
      "Epoch 418/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3867e-05 - val_loss: 8.8555e-05\n",
      "Epoch 419/500\n",
      "26745/26745 [==============================] - 2s 77us/step - loss: 7.3867e-05 - val_loss: 8.8555e-05\n",
      "Epoch 420/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3866e-05 - val_loss: 8.8555e-05\n",
      "Epoch 421/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3866e-05 - val_loss: 8.8555e-05\n",
      "Epoch 422/500\n",
      "26745/26745 [==============================] - 2s 70us/step - loss: 7.3866e-05 - val_loss: 8.8554e-05\n",
      "Epoch 423/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3866e-05 - val_loss: 8.8554e-05\n",
      "Epoch 424/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3866e-05 - val_loss: 8.8554e-05\n",
      "Epoch 425/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3865e-05 - val_loss: 8.8554e-05\n",
      "Epoch 426/500\n",
      "26745/26745 [==============================] - 2s 62us/step - loss: 7.3865e-05 - val_loss: 8.8554e-05\n",
      "Epoch 427/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3865e-05 - val_loss: 8.8553e-05\n",
      "Epoch 428/500\n",
      "26745/26745 [==============================] - 2s 76us/step - loss: 7.3865e-05 - val_loss: 8.8553e-05\n",
      "Epoch 429/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.3865e-05 - val_loss: 8.8553e-05\n",
      "Epoch 430/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3865e-05 - val_loss: 8.8553e-05\n",
      "Epoch 431/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3864e-05 - val_loss: 8.8553e-05\n",
      "Epoch 432/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3864e-05 - val_loss: 8.8552e-05\n",
      "Epoch 433/500\n",
      "26745/26745 [==============================] - 2s 70us/step - loss: 7.3864e-05 - val_loss: 8.8552e-05\n",
      "Epoch 434/500\n",
      "26745/26745 [==============================] - 2s 70us/step - loss: 7.3864e-05 - val_loss: 8.8552e-05\n",
      "Epoch 435/500\n",
      "26745/26745 [==============================] - 2s 69us/step - loss: 7.3864e-05 - val_loss: 8.8552e-05\n",
      "Epoch 436/500\n",
      "26745/26745 [==============================] - 2s 69us/step - loss: 7.3863e-05 - val_loss: 8.8552e-05\n",
      "Epoch 437/500\n",
      "26745/26745 [==============================] - 2s 71us/step - loss: 7.3863e-05 - val_loss: 8.8552e-05- loss: 7.3855e-\n",
      "Epoch 438/500\n",
      "26745/26745 [==============================] - 2s 70us/step - loss: 7.3863e-05 - val_loss: 8.8551e-05\n",
      "Epoch 439/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.3863e-05 - val_loss: 8.8551e-05\n",
      "Epoch 440/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.3863e-05 - val_loss: 8.8551e-05\n",
      "Epoch 441/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3862e-05 - val_loss: 8.8551e-05\n",
      "Epoch 442/500\n",
      "26745/26745 [==============================] - 2s 71us/step - loss: 7.3862e-05 - val_loss: 8.8551e-05\n",
      "Epoch 443/500\n",
      "26745/26745 [==============================] - 2s 69us/step - loss: 7.3862e-05 - val_loss: 8.8551e-05\n",
      "Epoch 444/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3862e-05 - val_loss: 8.8550e-05\n",
      "Epoch 445/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3862e-05 - val_loss: 8.8550e-05\n",
      "Epoch 446/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3862e-05 - val_loss: 8.8550e-05\n",
      "Epoch 447/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3861e-05 - val_loss: 8.8550e-05\n",
      "Epoch 448/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3861e-05 - val_loss: 8.8550e-05\n",
      "Epoch 449/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3861e-05 - val_loss: 8.8550e-05\n",
      "Epoch 450/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3861e-05 - val_loss: 8.8550e-05\n",
      "Epoch 451/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3861e-05 - val_loss: 8.8549e-05\n",
      "Epoch 452/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3861e-05 - val_loss: 8.8549e-05\n",
      "Epoch 453/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3860e-05 - val_loss: 8.8549e-05\n",
      "Epoch 454/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.3860e-05 - val_loss: 8.8549e-05\n",
      "Epoch 455/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.3860e-05 - val_loss: 8.8549e-05\n",
      "Epoch 456/500\n",
      "26745/26745 [==============================] - 2s 68us/step - loss: 7.3860e-05 - val_loss: 8.8549e-05\n",
      "Epoch 457/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3860e-05 - val_loss: 8.8548e-05\n",
      "Epoch 458/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3860e-05 - val_loss: 8.8548e-05\n",
      "Epoch 459/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3860e-05 - val_loss: 8.8548e-05\n",
      "Epoch 460/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3859e-05 - val_loss: 8.8548e-05\n",
      "Epoch 461/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3859e-05 - val_loss: 8.8548e-05\n",
      "Epoch 462/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3859e-05 - val_loss: 8.8548e-05\n",
      "Epoch 463/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3859e-05 - val_loss: 8.8548e-05\n",
      "Epoch 464/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3859e-05 - val_loss: 8.8547e-05\n",
      "Epoch 465/500\n",
      "26745/26745 [==============================] - ETA: 0s - loss: 7.3852e-05- ETA: 1 - 2s 66us/step - loss: 7.3859e-05 - val_loss: 8.8547e-05\n",
      "Epoch 466/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3858e-05 - val_loss: 8.8547e-05\n",
      "Epoch 467/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3858e-05 - val_loss: 8.8547e-05\n",
      "Epoch 468/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3858e-05 - val_loss: 8.8547e-05\n",
      "Epoch 469/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3858e-05 - val_loss: 8.8547e-05\n",
      "Epoch 470/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3858e-05 - val_loss: 8.8547e-05\n",
      "Epoch 471/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3858e-05 - val_loss: 8.8546e-05\n",
      "Epoch 472/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3858e-05 - val_loss: 8.8546e-05\n",
      "Epoch 473/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3857e-05 - val_loss: 8.8546e-05\n",
      "Epoch 474/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3857e-05 - val_loss: 8.8546e-05\n",
      "Epoch 475/500\n",
      "26745/26745 [==============================] - 2s 67us/step - loss: 7.3857e-05 - val_loss: 8.8546e-05\n",
      "Epoch 476/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3857e-05 - val_loss: 8.8546e-05\n",
      "Epoch 477/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3857e-05 - val_loss: 8.8546e-05\n",
      "Epoch 478/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3857e-05 - val_loss: 8.8546e-05\n",
      "Epoch 479/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3857e-05 - val_loss: 8.8545e-05\n",
      "Epoch 480/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3856e-05 - val_loss: 8.8545e-05\n",
      "Epoch 481/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3856e-05 - val_loss: 8.8545e-05\n",
      "Epoch 482/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3856e-05 - val_loss: 8.8545e-05\n",
      "Epoch 483/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3856e-05 - val_loss: 8.8545e-05\n",
      "Epoch 484/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3856e-05 - val_loss: 8.8545e-05\n",
      "Epoch 485/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3856e-05 - val_loss: 8.8545e-05\n",
      "Epoch 486/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3856e-05 - val_loss: 8.8545e-05\n",
      "Epoch 487/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3856e-05 - val_loss: 8.8544e-05\n",
      "Epoch 488/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3855e-05 - val_loss: 8.8544e-05\n",
      "Epoch 489/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3855e-05 - val_loss: 8.8544e-05\n",
      "Epoch 490/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3855e-05 - val_loss: 8.8544e-05\n",
      "Epoch 491/500\n",
      "26745/26745 [==============================] - 2s 66us/step - loss: 7.3855e-05 - val_loss: 8.8544e-05\n",
      "Epoch 492/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3855e-05 - val_loss: 8.8544e-05\n",
      "Epoch 493/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3855e-05 - val_loss: 8.8544e-05\n",
      "Epoch 494/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3855e-05 - val_loss: 8.8544e-05\n",
      "Epoch 495/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3855e-05 - val_loss: 8.8544e-05\n",
      "Epoch 496/500\n",
      "26745/26745 [==============================] - 2s 63us/step - loss: 7.3854e-05 - val_loss: 8.8543e-05\n",
      "Epoch 497/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3854e-05 - val_loss: 8.8543e-05\n",
      "Epoch 498/500\n",
      "26745/26745 [==============================] - 2s 64us/step - loss: 7.3854e-05 - val_loss: 8.8543e-05\n",
      "Epoch 499/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3854e-05 - val_loss: 8.8543e-05\n",
      "Epoch 500/500\n",
      "26745/26745 [==============================] - 2s 65us/step - loss: 7.3854e-05 - val_loss: 8.8543e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bde0a961d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=500,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
